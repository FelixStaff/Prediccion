{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--context', type=int, default=100)\n",
    "parser.add_argument('--future', type=int, default=10)\n",
    "\n",
    "args = parser.parse_args()\n",
    "print(args.context)\n",
    "print(args.future)\n",
    "def LinearCell(num_input, num_hidden, Dropout=0):\n",
    "    Seq = nn.Sequential(\n",
    "        nn.Linear(num_input,num_hidden),\n",
    "        nn.LeakyReLU(0.8),\n",
    "        nn.Dropout(Dropout)\n",
    "    )\n",
    "    return Seq\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size,num_layers, num_linear =1):\n",
    "        \"\"\"\n",
    "        input_size: input size\n",
    "        hidden_size: hidden size\n",
    "        output_size: output size\n",
    "        num_layers: number of layers\n",
    "        num_linear: number of linear layers\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        LinearSeq = []\n",
    "        for i in range(num_linear):\n",
    "            LinearSeq.append(LinearCell(hidden_size,hidden_size,Dropout=0))\n",
    "        self.LinearSeq = nn.Sequential(*LinearSeq)\n",
    "        self.L1 = LinearCell(hidden_size,hidden_size,Dropout=0)\n",
    "        self.L2 = LinearCell(hidden_size,hidden_size,Dropout=0)\n",
    "        self.LOut = LinearCell(hidden_size,output_size)\n",
    "        self.init_weights()\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.normal_(m.bias)\n",
    "    def forward(self,x,future=0):\n",
    "        \"\"\"\n",
    "        x: input [sequence_length,batch_size,input_size]\n",
    "        sequence_length: sequence length\n",
    "        batch_size: batch size\n",
    "        input_size: input size == 15\n",
    "        future: number of future predictions\n",
    "        \"\"\"\n",
    "        # outputs\n",
    "        outputs = []\n",
    "        h_t = torch.zeros(self.num_layers,1,self.hidden_size)\n",
    "        c_t = torch.zeros(self.num_layers,1,self.hidden_size)\n",
    "        \n",
    "        for input_t in x.split(1,dim=0):\n",
    "            out, (h_t,c_t) = self.lstm1(input_t,(h_t,c_t))\n",
    "            #print (out.shape)\n",
    "            out = self.LinearSeq(out)\n",
    "            l1 = self.L1(out)\n",
    "            l2 = self.L2(l1)\n",
    "            output = self.LOut(l2)\n",
    "            outputs.append(output)\n",
    "        \n",
    "        for i in range(future):\n",
    "            out, (h_t,c_t) = self.lstm1(output, (h_t,c_t))\n",
    "            out = self.LinearSeq(out)\n",
    "            l1 = self.L1 (out)\n",
    "            l2 = self.L2(l1)\n",
    "            output = self.LOut(l2)\n",
    "            outputs.append(output)\n",
    "        outputs = torch.cat(outputs,dim=0)\n",
    "        return outputs\n",
    "# load model weights\n",
    "input_size = 15\n",
    "argument = {\n",
    "    'input_size' : input_size,\n",
    "    'hidden_size' : 18,\n",
    "    'output_size' : input_size,\n",
    "    'num_layers' : 3,\n",
    "    'num_linear' : 2\n",
    "}\n",
    "model = Net(**argument)\n",
    "model.load_state_dict(torch.load('Model/modelApodaca4.2.pt'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('MLearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9178488e902897ccede7ccf72145ea4bf1db4863c1b153f9ec9b532ffe6212a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
